---
title: "STAT 331 Portfolio"
author: "Emily Lo"
format: 
  html: 
    self-contained: true
    code-overflow: wrap
    code-tools: true
    code-fold: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
  errors: true
  warning: false
  messages: false
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an B-

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r wd-1-csv}
#Lab 4 Q0
avocado <- read_csv(here("week 4","lab4", "avocado.csv"))

```

-   `xlsx`

```{r wd-1-xlsx}
#Practice activity 4 Q1
military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip = 7, 
                      n_max = 190)
```

-   `txt`

```{r wd-1-txt}
#Practice activity 5.2 
message <- read_csv(here::here("scrambled_message.txt"))
```

**WD-2: I can select necessary columns from a dataset.**

```{r wd-2}
#Challenge 9 Q10

Allan_total_percentage <- cleaned_names |> 
  filter(Year == 2000,
         State %in% c("CA","PA"),
         Name %in% c("Allan", "Alan", "Allen")) |>
  group_by(State, Name) |>
  summarize(total = sum(Count), 
            .groups = "drop") |>
  mutate(prop = total / sum(total)) |>
  group_by(State) |>
  ungroup() |> 
  select(-total) |>
  pivot_wider(names_from = Name, 
              values_from = prop, 
              values_fill = 0)

Allan_percent_table <- gt(Allan_total_percentage) |>
  fmt_percent(columns = 2:4, decimals = 2) |>
  tab_header(
    title = md("**<span style = 'color:#BA55D3;'>Frequency of Allans</span>**"),
    subtitle = ("Year: 2000")) |>
  tab_style(
    style = list(
      cell_text(font = "Georgia",
                weight = "bold",
                size = "14px",
                align = "right")),
    locations = cells_body())


Allan_percent_table
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-3-numeric}
# Lab 4 Q3
clean_avocado |> 
  semi_join(regions_major, by = "region") |>
 filter(year == 2017 ,  
          type == "organic") |>
  group_by(region) |>
  summarize(sum_region = sum(`Small/Medium`)) |>
  slice_max(sum_region)
```

-   character -- specifically a string

```{r wd-3-string}
#Practice Activity 5.2 Q2
message |>
  filter(str_detect(Word, pattern = "\\w")) |> 
  count() 
```

-   factor

```{r wd-3-factor}
# Lab 4 Q3
clean_avocado |> 
  semi_join(regions_major, by = "region") |>
 filter(year == 2017, type == "organic") |>
  group_by(region) |>
  summarise(sum_region = sum(`Small/Medium`)) |>
  slice_max(sum_region)

```

-   date

```{r wd-3-date}
#Pratice exercise 5.1 question 3 
thanks <- ymd("2018-11-22")
time_frame <- (thanks - days(35)) %--% (thanks + days(35))
suspects <- suspects |>
  filter(Time.Spotted %within% time_frame)
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-4-numeric}
#Lab 4 Q6 (revised)
regions_cali <- tibble(region = c("LosAngeles","SanDiego", 
                                  "Sacramento", "SanFrancisco"))

final_cali <- clean_avocado |> 
  semi_join(regions_cali, by = "region") |>
  group_by(region, type) |>
  summarize(average_price = mean(AveragePrice)) |> 
  pivot_wider(names_from = type, values_from = average_price) |>
  mutate(difference = organic - conventional)

ggplot(data = final_cali, 
       aes(x = region, y = difference)) + 
       geom_col() + 
  labs(x = "Region of CA", y = " ", 
       title = "Avearge difference in price of organic versus conventional avocados by region")

```

-   character -- specifically a string

```{r wd-4-string}
#Practice activity 5.2 Decode a message Q5
words <- str_replace_all(words, pattern = "z", replace = "t")

```

-   factor

```{r wd-4-factor}
#lab 5 Capture over the week Q3 (revised)

week_day_level <- fct_collapse(rodents$day_of_week, 
      "weekday" = c("Mon", "Tue", "Wed", "Thu", "Fri"),
      "weekend" = c("Sat", "Sun"))

ggplot(data= rodents, 
       aes(x = week_day_level, 
           y = captured_rodents)) +
  geom_bar(stat = "identity") +
  labs(x = "Time of Week", 
       y = "", 
       title = "Number of Rodents Captured During Weekday and Weekend")

```

-   date

```{r wd-4-date}
#Lab 5 Time Series Q1 
summarized_data <- surveys |> 
  mutate(date = ymd(date))

ggplot(data = summarized_data, 
       aes(x = year(date), 
           y = weight, 
           color = genus)) +
  geom_line() +
  theme_classic() +
  scale_x_continuous(limits = c(1977, 2002)) +
  scale_color_discrete(guide = guide_legend(title = "Genus")) +
  labs(x = "Year", 
       y = " ", 
       title = "Variation of Weights(g) for each Genus of Rodent over Time")


```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left}

```

-   `right_join()`

```{r wd-5-right}

```

-   `inner_join()`

```{r wd-5-inner}
# Preview Activity 4.3 Practice with Joins Q1

inner_join(prof_info, prof_course)
```

-   `full_join()`

```{r wd-5-full}
# Preview Activity 4.3 Practice with Joins Q2

full_join(prof_info, prof_course)
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r wd-6-semi}
#lab 4 Q3
clean_avocado |> 
  semi_join(regions_major, by = "region") |>
 filter(year == 2017 ,  
          type == "organic") |>
  group_by(region) |>
  summarize(sum_region = sum(`Small/Medium`)) |>
  slice_max(sum_region)
```

-   `anti_join()`

```{r wd-6-anti}
#Lab 4 Q5 (revised)
other_regions <- tibble(region = c("California", "NewYork", 
                                   "SouthCarolina", "TotalUS",
                                   "West","GreatLakes",
                                   "Midsouth", "Northeast", 
                                   "Plains", "SouthCentral", 
                                   "Southeast"))
                                   
top_5 <- clean_avocado |> 
  anti_join(other_regions, by = "region") |>
  group_by(region) |>
  summarize(region_mean = mean(`Total Volume`)) |>
  slice_max(region_mean, n=5) 

clean_avocado |> 
semi_join(top_5, by = "region") |>
ggplot(mapping = aes(x = `Total Volume`, y = region)) + 
  geom_boxplot() + 
  geom_jitter() +
  labs(y="Region", x=" ", 
       title = "Five Regions with the Highest Averages for the Total Volume Variable")

```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r wd-7-long}
#Lab 4 Q7 (revised)
avocado_size <- clean_avocado |>
  semi_join(regions_cali, by = "region") |>
  pivot_longer(cols = c("Small/Medium", "Large", "Extra Large"), 
               names_to = "Size", 
               values_to = "Volume") |>
  group_by(region, type, Size) |>
  summarize(volume_sold = sum(Volume))

ggplot(data = avocado_size, 
       mapping = aes(x = region, 
                     y = volume_sold, 
                     fill = Size)) + 
  geom_bar(position = "fill", 
           stat = "identity") + 
  facet_wrap(.~type) + 
  scale_x_discrete(guide = guide_axis(n.dodge = 3)) + 
  labs(x = "Region of CA", 
       y = "Proportion of Mean Avocados Sold", 
       fill = "Avocado Size")

# I learned about lables = scales:number_format on https://scales.r-lib.org/reference/number_format.html
```

-   `pivot_wider()`

```{r wd-7-wide}
#Lab 4 Q6 (revised, reduced number of objects)
regions_cali <- tibble(region = c("LosAngeles","SanDiego", 
                                  "Sacramento", "SanFrancisco"))

final_cali <- clean_avocado |> 
  semi_join(regions_cali, by = "region") |>
  group_by(region, type) |>
  summarize(average_price = mean(AveragePrice)) |> 
  pivot_wider(names_from = type, values_from = average_price) |>
  mutate(difference = organic - conventional)

ggplot(data = final_cali, 
       aes(x = region, y = difference)) + 
       geom_col() + 
  labs(x = "Region of CA", y = " ", 
       title = "Avearge difference in price of organic versus conventional avocados by region")


```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I have done this in the following assignments:

Challenge 8, Lab 7, Challenge 7

**R-2: I can write well documented and tidy code.**

-   Example 1

```{r r-2-1}
#Challenge 8 Step 2
xmas2 <- xmas |> 
  mutate(day.num = as.character(english::english(Day)),
   Full.Phrase = pmap_chr(.l = list(
           day = Day,
           num_word = day.num,
           item = Gift.Item,
           verb = Verb,
           adjective = Adjective,
           location = Location),
           .f = make_phrase)
  )

```

-   Example 2

```{r r-2-2}
#Lab 7 Q3.1
rescale_01 <- function(vec){
  stopifnot(is.vector(vec), 
            is.numeric(vec), 
            length(vec) > 1, 
            !any(is.na(vec)))
  min <- min(vec, na.rm = TRUE)
  (vec - min) / (max(vec, na.rm = TRUE) - min)
}

rescale_01 <- function(vec){
  stopifnot(is.vector(vec), 
            is.numeric(vec), 
            length(vec) > 1)
  min <- min(vec, na.rm = TRUE)
  (vec - min) / (max(vec, na.rm = TRUE) - min)
}

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1

```{r r-3-1}
#Lab 7 Q3.5
rescale_column <- function(data, var) {
  stopifnot(is.data.frame(data), 
            is.character(var))
  data |> 
    mutate(across(.cols = all_of(var), .fns = ~ rescale_01(.x)))
}

# I learned about all_of on https://tidyselect.r-lib.org/reference/all_of.html
```

-   Example 2

```{r r-3-2}
#Lab 7 Q3.1
rescale_01 <- function(vec){
  stopifnot(is.vector(vec), 
            is.numeric(vec), 
            length(vec) > 1, 
            !any(is.na(vec)))
  min <- min(vec, na.rm = TRUE)
  (vec - min) / (max(vec, na.rm = TRUE) - min)
}

rescale_01 <- function(vec){
  stopifnot(is.vector(vec), 
            is.numeric(vec), 
            length(vec) > 1)
  min <- min(vec, na.rm = TRUE)
  (vec - min) / (max(vec, na.rm = TRUE) - min)
}

```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables

```{r dvs-1-num}
#Lab 7 Q3.4 (revised)

#| layout-ncol: 1
ggplot(data = fishes_data, mapping = aes(x = length)) +
geom_histogram(fill = "purple") +
  labs(title = "Original Length Values for the Number of Trout",
       x = "length of trout",
       y = "")

rescaled_data <- fishes_data |>
  mutate(rescaled_length = rescale_01(length)) 

ggplot(data = rescaled_data, mapping = aes(x = rescaled_length)) +
  geom_histogram(fill = "lightblue") +
  labs(title = "Rescaled Length Values for the Number of Trout",
       x = "length of trout",
       y = "")

#quarto.org/docs/interactive/layout.html to learn about the quarto styles for layout-nol:1
```

-   numeric variables and categorical variables

```{r dvs-2-num-cat}
#Challenge 2
ggplot(data = surveys, 
       mapping = aes(x = weight, 
                     y = species)) + 
  geom_density_ridges() + 
       labs(x = "Weight", 
            y = " ", 
            title = "Distribution of Weight Within Each Species")


```

-   categorical variables

```{r}
#Lab 5 Captures over the week question 1 (revised)

rodents <- surveys |> 
  group_by(day_of_week) |>
  summarize(captured_rodents = n()) |> 
  drop_na()

ggplot(data= rodents, 
       aes(x = reorder(day_of_week, 
                       captured_rodents), 
           y = captured_rodents)) +
  geom_bar(stat = "identity") +
  labs(x = "Day of Week", 
       y = " ", 
       title = "Number of Rodents Captured Each Day of the Week") 
```

-   dates

```{r dvs-2-date}
#Lab 5 time series Q1
summarized_data <- surveys |> 
  mutate(date = ymd(date))

ggplot(data = summarized_data, 
       aes(x = year(date), 
           y = weight, 
           color = genus)) +
  geom_line() +
  theme_classic() +
  scale_x_continuous(limits = c(1977, 2002)) +
  scale_color_discrete(guide = guide_legend(title = "Genus")) +
  labs(x = "Year", 
       y = " ", 
       title = "Variation of Weights(g) for each Genus of Rodent over Time")
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1

```{r dvs-2-1}
#Lab 5 Captures over the week question 1 

rodents <- surveys |> 
  group_by(day_of_week) |>
  summarize(captured_rodents = n()) |> 
  drop_na()

ggplot(data= rodents, 
       aes(x = reorder(day_of_week, 
                       captured_rodents), 
           y = captured_rodents)) +
  geom_bar(stat = "identity") +
  labs(x = "Day of Week", 
       y = " ", 
       title = "Number of Rodents Captured Each Day of the Week") 
```

-   Example 2

```{r dvs-2-2}
#Lab 4 Q7 (revised)
avocado_size <- clean_avocado |>
  semi_join(regions_cali, by = "region") |>
  pivot_longer(cols = c("Small/Medium", "Large", "Extra Large"), 
               names_to = "Size", 
               values_to = "Volume") |>
  group_by(region, type, Size) |>
  summarize(volume_sold = sum(Volume))

ggplot(data = avocado_size, 
       mapping = aes(x = region, 
                     y = volume_sold, 
                     fill = Size)) + 
  geom_bar(position = "fill", 
           stat = "identity") + 
  facet_wrap(.~type) + 
  scale_x_discrete(guide = guide_axis(n.dodge = 3)) + 
  labs(x = "Region of CA", 
       y = "Proportion of Mean Avocados Sold", 
       fill = "Avocado Size")

# I learned about lables = scales:number_format on https://scales.r-lib.org/reference/number_format.html. I learned about n.dodge on https://ggplot2.tidyverse.org/reference/guide_axis.html
```

**DVS-3: I show creativity in my visualizations**

-   Example 1

```{r dvs-3-1}
# Challenge 7 Part 3 

my_palette <- c("#00FFFF", "#90EE90")

ggplot(data = fish_visual, 
       aes(x = year, 
           y = average_condition_index,
           color = as.factor(trip))) + 
  geom_line() + 
  facet_wrap(~ species, 
             ncol = 2) + 
  labs(y = "", 
       x = "Year") +
  scale_color_manual(values = my_palette) +
    labs(title = str_c("Trout Condition Index of ",
      "<span style = 'color : #00FFFF'>**Trip 1**</span>",
      " and <span style = 'color:#90EE90'>**Trip 2**</span>"),
      subtitle = "By Year") +
  theme_gray() +
  theme(panel.grid = element_blank(),
        axis.line = element_line(size = 0.5, 
                                 color = "pink"),
        plot.title = element_markdown(size = 15), 
        axis.text.y = element_text(size = 12), 
        plot.background = element_rect(fill = "grey90", color = "black", linewidth = 1), 
        strip.background = element_rect(colour = "red", 
                                        fill = "pink"),
        legend.position = "none")
```

-   Example 2

```{r dvs-3-2}
#Lab 7 Q2.2

my_palette <- c("#00BFFF", "#BA55D3")


fish_missing_visualization <- fishes_data |>  
  filter(is.na(weight)) |> 
  select(weight, trip, year, section) |> 
  mutate(trip = if_else(trip == 1, 
                        "Trip 1", 
                        "Trip 2"),
          year = factor(year, 
                        levels = 1989:2006))

ggplot(data = fish_missing_visualization, 
       aes(y = year, 
           fill = section)) +
  geom_bar() + 
  facet_wrap(~trip) + 
  scale_fill_manual(values = my_palette) +
  labs(title = str_c("Missing Fish Weights for ",
  "<span style = 'color:#00BFFF'>**Johnsrud**</span>",
      " and <span style = 'color:#BA55D3'>**ScottyBrown**</span>",
   " Section of Blackfoot River by Trip"), 
       x = "",
       y = "") +
  theme_gray() +
    scale_x_continuous(breaks = seq(0, 400, 25)) +
  scale_y_discrete(drop = FALSE) + 
  theme(panel.grid.major = element_line(color = "gray80", 
                                        size = 0.5),
        panel.grid.minor = element_blank(),
        axis.line = element_line(size = 0.5, 
                                 color = "gray"),
        axis.text.y = element_text(size = 10), 
        legend.position = "none",
        plot.title = element_markdown(size = 14))


# I also learned about adding features to the plot like legend position and grid lines on https://r-graphics.org/recipe-legend-position. 
# I also learned to change the font size larger on the y-axis to help the reader easily read the different years. I learned this on 
#https://statisticsglobe.com/change-font-size-of-ggplot2-plot-in-r-axis-text-main-title-legend.
# I learned about scale_y_discrete(drop = FALSE) to add the years that have no observations on https://ggplot2.tidyverse.org/reference/scale_discrete.html

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1

```{r dvs-4-1}
#Challenge 7 Part 3
fish_visual <- fishes_data |> 
  group_by(year, 
           species, 
           trip) |> 
  summarize(average_condition_index = mean(condition_index, 
                                           na.rm = TRUE))

```

-   Example 2

```{r dvs-4-2}
#Lab 4 Q3
clean_avocado |> 
  semi_join(regions_major, by = "region") |>
 filter(year == 2017 ,  
          type == "organic") |>
  group_by(region) |>
  summarize(sum_region = sum(`Small/Medium`)) |>
  slice_max(sum_region)
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r dvs-5-1}
#Lab 4 Q7 (revised)
avocado_size <- clean_avocado |>
  semi_join(regions_cali, by = "region") |>
  pivot_longer(cols = c("Small/Medium", "Large", "Extra Large"), 
               names_to = "Size", 
               values_to = "Volume") |>
  group_by(region, type, Size) |>
  summarize(volume_sold = sum(Volume))

ggplot(data = avocado_size, 
       mapping = aes(x = region, 
                     y = volume_sold, 
                     fill = Size)) + 
  geom_bar(position = "fill", 
           stat = "identity") + 
  facet_wrap(.~type) + 
  scale_x_discrete(guide = guide_axis(n.dodge = 3)) + 
  labs(x = "Region of CA", 
       y = "Proportion of Mean Avocados Sold", 
       fill = "Avocado Size")

# I learned about lables = scales:number_format on https://scales.r-lib.org/reference/number_format.html. I learned about n.dodge on https://ggplot2.tidyverse.org/reference/guide_axis.html
```

-   Example 2

```{r dvs-5-2}
#Lab 4 Q6 (revised)
regions_cali <- tibble(region = c("LosAngeles","SanDiego", 
                                  "Sacramento", "SanFrancisco"))

final_cali <- clean_avocado |> 
  semi_join(regions_cali, by = "region") |>
  group_by(region, type) |>
  summarize(average_price = mean(AveragePrice)) |> 
  pivot_wider(names_from = type, values_from = average_price) |>
  mutate(difference = organic - conventional)

ggplot(data = final_cali, 
       aes(x = region, y = difference)) + 
       geom_col() + 
  labs(x = "Region of CA", y = " ", 
       title = "Avearge difference in price of organic versus conventional avocados by region")
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r dvs-6-1}
# Challenge 9 Q3

cleaned_names_table <- cleaned_names |>
  filter(Name == "Allison") |>
  group_by(State, Sex) |>
  summarize(Count = sum(Count), 
            .groups = "drop") |>
  pivot_wider(names_from = Sex, 
              values_from = Count, 
              values_fill = 0) |>
  gt() |>
  tab_header(
    title = md("**Frequency Table of Babies Named Allison**"),
    subtitle = "for 192,825 babies"
  ) |>
  cols_label(
    F = "Female",
    M = "Male")

cleaned_names_table
```

-   Example 2

```{r dvs-6-2}
#Challenge 9 Q4
allison_lm <- lm(total ~ Year, 
                 data = allison_totals)

allison_tidy_table <- broom::tidy(allison_lm) |>
  gt() |>
  tab_header(
    title = md("**Regression Results Table**")) |> 
  tab_style(
    style = list(
      cell_text(font = "Times", 
                weight = "lighter", 
                size = "11px")),
    locations = cells_body(columns = everything(), 
                           rows = 1:2)
  )
  
allison_tidy_table
```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r dvs-7-1}
#Challenge 9 Q9
Allan_totals <- cleaned_names |> 
  filter(Year == 2000,
         State %in% c("CA","PA"),
         Name %in% c("Allan", 
         "Alan", 
         "Allen")) |>
  group_by(State, Name) |>
  summarize(total = sum(Count), 
            .groups = "drop") |>
  pivot_wider(names_from = Name, 
              values_from = total,
              values_fill = 0)

Allan_table <- gt(Allan_totals) |>
  tab_header(
    title = md("**Frequency of Allans**"),
    subtitle = ("Year: 2000")) |>
  tab_style(
    style = list(
      cell_borders(sides = "all", 
                   color = "#87CEEB",
                   weight = px(1.5),
                   style = "solid"
                     ),
      cell_fill(color = "#FFC0CB", alpha = NULL),
      cell_text(font = "Impact", 
                weight = "lighter", 
                size = "14px")),
    locations = cells_body()) 

Allan_table

# I learned how to tab_style on https://gt.rstudio.com/reference/tab_style.html. I think that it can make your table more creative. 
```

-   Example 2

```{r dvs-7-2}
#Challenge 9 Q10

Allan_total_percentage <- cleaned_names |> 
  filter(Year == 2000,
         State %in% c("CA","PA"),
         Name %in% c("Allan", "Alan", "Allen")) |>
  group_by(State, Name) |>
  summarize(total = sum(Count), 
            .groups = "drop") |>
  mutate(prop = total / sum(total)) |>
  group_by(State) |>
  ungroup() |> 
  select(-total) |>
  pivot_wider(names_from = Name, 
              values_from = prop, 
              values_fill = 0)

Allan_percent_table <- gt(Allan_total_percentage) |>
  fmt_percent(columns = 2:4, decimals = 2) |>
  tab_header(
    title = md("**<span style = 'color:#BA55D3;'>Frequency of Allans</span>**"),
    subtitle = ("Year: 2000")) |>
  tab_style(
    style = list(
      cell_text(font = "Georgia",
                weight = "bold",
                size = "14px",
                align = "right")),
    locations = cells_body())


Allan_percent_table
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call

```{r pe-1-one-call}
#Challegne 8 Step 3 
sing_day <- function(dataset, line, phrase_col){
  
  # Step 1: Setup the intro line
  num_word <- english::ordinal(line) 
  intro <- glue::glue("On the {num_word} day of Christmas, my true love sent to me:")

  # Step 2: Sing the gift phrases
  phrases <- dataset |> pull( {{phrase_col}} )
  if (line > 1) {
    last_phrase <- str_c("and ", phrases[1])
    phrases <- c(phrases[line:2], last_phrase)
  }
  if (line == 1){
    phrases <- phrases[1]
  }
 
  lyrics <- str_c(phrases, ifelse(line == 1, "", ","))    
  lyrics[length(lyrics)] <- str_replace(last(lyrics),",", ".")  
    
  lyrics <- str_flatten(lyrics, collapse = "\n")
  sing_line <- glue::glue("{intro}\n{lyrics}\n\n")
  
  return(sing_line)
}


sing_day(dataset = xmas2, 
         line = 6, 
         phrase_col = Full.Phrase)

#i learned using "last" from https://www.rdocumentation.org/packages/data.table/versions/1.14.8/topics/last. I also  could of replaced it with lyrics[length(lyrics)]
```

-   `across()`

```{r pe-1-across}
#Lab 7 Q2.1 (revised)
fishes_data |>
  summarize(across(.cols = everything(), 
                   .fns = ~ sum(is.na(.x))))
  

```

-   `map()` functions

```{r pe-1-map-1}
#Challenge 8 Step 2
xmas2 <- xmas |> 
  mutate(day.num = as.character(english::english(Day)),
   Full.Phrase = pmap_chr(.l = list(
           day = Day,
           num_word = day.num,
           item = Gift.Item,
           verb = Verb,
           adjective = Adjective,
           location = Location),
           .f = make_phrase)
  )

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1

```{r pe2-1}
#Challenge 8 Step 3
sing_day <- function(dataset, line, phrase_col){
  
  # Step 1: Setup the intro line
  num_word <- english::ordinal(line) 
  intro <- glue::glue("On the {num_word} day of Christmas, my true love sent to me:")

  # Step 2: Sing the gift phrases
  phrases <- dataset |> pull( {{phrase_col}} )
  if (line > 1) {
    last_phrase <- str_c("and ", phrases[1])
    phrases <- c(phrases[line:2], last_phrase)
  }
  if (line == 1){
    phrases <- phrases[1]
  }
 
  lyrics <- str_c(phrases, ifelse(line == 1, "", ","))    
  lyrics[length(lyrics)] <- str_replace(last(lyrics),",", ".")  
    
  lyrics <- str_flatten(lyrics, collapse = "\n")
  sing_line <- glue::glue("{intro}\n{lyrics}\n\n")
  
  return(sing_line)
}

#i learned using "last" from https://www.rdocumentation.org/packages/data.table/versions/1.14.8/topics/last. I also  could of replaced it with lyrics[length(lyrics)]
```

-   Example 2

```{r pe2-2}
#Challenge 8 Step 2
xmas2 <- xmas |> 
  mutate(day.num = as.character(english::english(Day)),
   Full.Phrase = pmap_chr(.l = list(
           day = Day,
           num_word = day.num,
           item = Gift.Item,
           verb = Verb,
           adjective = Adjective,
           location = Location),
           .f = make_phrase)
  )
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r pe-3-across}
#Lab 7 Q2.1
fishes_data |>
  summarize(across(.cols = everything(), 
                   .fns = ~ sum(is.na(.x))))
```

-   `map()` functions (Provide 2 Examples)

```{r pe-3-map-1}
xmas2 <- xmas |> 
  mutate(day.num = as.character(english::english(Day)),
   Full.Phrase = pmap_chr(.l = list(
           day = Day,
           num_word = day.num,
           item = Gift.Item,
           verb = Verb,
           adjective = Adjective,
           location = Location),
           .f = make_phrase)
  )
```

```{r pe-3-map-2}
map_chr(1:12, ~ sing_day(xmas2, .x, Full.Phrase)) |>
str_c(collapse = "\n") |>
  cat()
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1

```{r pe-4-1}
#Lab4 Q7
fishes_data |>
  summarize(across(.cols = everything(), 
                   .fns = ~ sum(is.na(.x))))
  
```

-   Example 2

```{r pe-4-2}
#Lab 4 Q3
clean_avocado |> 
  semi_join(regions_major, by = "region") |>
 filter(year == 2017 ,  
          type == "organic") |>
  group_by(region) |>
  summarize(sum_region = sum(`Small/Medium`)) |>
  slice_max(sum_region)
```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r dsm-1-1}
#practice activity 9.2 simulation
qnif(p = .95, min = 1.5, max = 3.5)
qnorm(p = 0.1, mean = 4.6, sd = 0.8)
dnorm(x = 5, mean = 4.6, sd = 0.8)
dchisq(x = 5, df = 4)
weight <- rnorm(n = 100, mean = 4.6, sd = 0.8)
sum(weight<4)


```

-   Example 2

```{r dsm-1-2}
#practice activity 9.2 simulation 

set.seed(1957)

music_man <- function(n_tromb, n_cor, n_reed){
  
  trombones <- rnorm(n_tromb, mean = 4.6, sd = 0.8)
  cornets <- runif(n_cor, min = 1.5, max = 3.5)
  reeds <- rchisq(n_reed, df = 4)
  
  return(sum(trombones) + sum(cornets) + sum(reeds))
}

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, n_cor = 110, n_reed = 1035)
                      ) 
sum(my_weights < 4532)
```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1

```{r dsm-2-1}
# Practice Activity 9.1 Q2 
mystery_animal_lm <- lm(weight_after ~ weight_before,
                        data = mystery_animal)
```

-   Example 2

```{r dsm-2-2}
# Challenge 9 Q4
allison_lm <- lm(total ~ Year, 
                 data = allison_totals)

allison_tidy_table <- broom::tidy(allison_lm) |>
  gt() |>
  tab_header(
    title = md("**Regression Results Table**")) |> 
  tab_style(
    style = list(
      cell_text(font = "Times", 
                weight = "lighter", 
                size = "11px")),
    locations = cells_body(columns = everything(), 
                           rows = 1:2)
  )
  
allison_tidy_table
```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

Because I had lots of revisions for each lab, I have took the time to read through the comments and reread my code to figure out how I can revise my code. I would use the help of online resources to advance my learning in these certain functions or topics. Then, afterwards, I take what I learn and revise my code.

I try my best to incorporate professor/peer feedback into future labs by reviewing what I did wrong in my previous labs before I submit my current lab. For example, in lab 2 I received feedback on adding a plot title, to eliminate the y-axis title, so people don't have to tilt their head to read it. I have ensured that my future plots in the future labs 3,4, and 5 do not have y-axis titles and that the title of the plot contains all information needed.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

I have used online resources to further develop my understanding and also find new functions that I can use that were not taught in class yet. For example, in DVS-2, I learned about n.dodge on https://ggplot2.tidyverse.org/reference/guide_axis.html.
In PE-2, I learned using "last" from https://www.rdocumentation.org/packages/data.table/versions/1.14.8/topics/last. I knew that I also could of replaced it with lyrics\[length(lyrics)\], but I wanted to experiment and try something unique and different. Also, in PE-4, I leanred about scale_x\_continueous and discrete through https://ggplot2.tidyverse.org/reference/scale_continuous.html.

## Peer Support & Collaboration

<!-- Include an image of feedback you gave that you are proud of (either in a peer review or in Discord) -->

I have always completed my peer reviews in a timely manner, with both positive and constructive feedback referring to specific questions in their labs. In addition, as a proactive and patient team member in my group, I am always actively engaged in group work as I have attended every class period and ensure that we finish assignments together after class, and that team members all have the same understanding of the topics by reviewing the assignment together.

An image of feedback I submitted as a peer review for lab 9.

Lightning round:

-   If Trenton doesn\'t earn an A, then nobody should, because he attended every class period, actively pays attention, and utilizes with the tools we learned in class.

    Functions was the most difficult part of class because it was hard for me to think about the steps before I start writing my code.

-   What was the easiest part of the class for you? Explain why.

I think making plots were pretty easy for me to understand because it was more straightforward to me and I am a visual learner so I enjoyed it.

-   What part of the class surprised or interested you the most? Explain why.

    The part where this class is a different grading schedule because i don't recall another professor who also does this.

-   Give one piece of advice to a student just beginning a quarter of STAT 331 that will help them be successful in learning.

coding in R requires a lot of patience, and remember that there is always time to improve
